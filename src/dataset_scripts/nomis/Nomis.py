import requests
import pandas as pd
import datetime
import os

def Employment_Conversion():

    date = datetime.datetime.now()
    formatted_date = date.strftime("%d-%m-%Y")
    urls = ["https://www.nomisweb.co.uk/api/v01/dataset/NM_17_5.data.csv?geography=1778384897...1778384901,1778384941,1778384950,1778385143...1778385146,1778385159,1778384902...1778384905,1778384942,1778384943,1778384956,1778384957,1778385033...1778385044,1778385124...1778385138,1778384906...1778384910,1778384958,1778385139...1778385142,1778385154...1778385158,1778384911...1778384914,1778384954,1778384955,1778384965...1778384972,1778385045...1778385058,1778385066...1778385072,1778384915...1778384917,1778384944,1778385078...1778385085,1778385100...1778385104,1778385112...1778385117,1778385147...1778385153,1778384925...1778384928,1778384948,1778384949,1778384960...1778384964,1778384986...1778384997,1778385015...1778385020,1778385059...1778385065,1778385086...1778385088,1778385118...1778385123,1778385160...1778385192,1778384929...1778384940,1778384953,1778384981...1778384985,1778385004...1778385014,1778385021...1778385032,1778385073...1778385077,1778385089...1778385099,1778385105...1778385111,1778384918...1778384924,1778384945...1778384947,1778384951,1778384952,1778384973...1778384980,1778384998...1778385003,1778384959,1778385193...1778385246&date=latest&variable=MAKE|Economically%20active%20-%20In%20employment%202|7|4&measures=20599,21001,21002,21003",
            "https://www.nomisweb.co.uk/api/v01/dataset/NM_17_5.data.csv?geography=1778384897...1778384901,1778384941,1778384950,1778385143...1778385146,1778385159,1778384902...1778384905,1778384942,1778384943,1778384956,1778384957,1778385033...1778385044,1778385124...1778385138,1778384906...1778384910,1778384958,1778385139...1778385142,1778385154...1778385158,1778384911...1778384914,1778384954,1778384955,1778384965...1778384972,1778385045...1778385058,1778385066...1778385072,1778384915...1778384917,1778384944,1778385078...1778385085,1778385100...1778385104,1778385112...1778385117,1778385147...1778385153,1778384925...1778384928,1778384948,1778384949,1778384960...1778384964,1778384986...1778384997,1778385015...1778385020,1778385059...1778385065,1778385086...1778385088,1778385118...1778385123,1778385160...1778385192,1778384929...1778384940,1778384953,1778384981...1778384985,1778385004...1778385014,1778385021...1778385032,1778385073...1778385077,1778385089...1778385099,1778385105...1778385111,1778384918...1778384924,1778384945...1778384947,1778384951,1778384952,1778384973...1778384980,1778384998...1778385003,1778384959,1778385193...1778385246&date=latest&variable=45,45&measures=20599,21001,21002,21003"]
    url_names= ["Number_of_Employed.csv","Employment_Percentage.csv"]

    # Downloads urls, merges the records into 1 and cleanses them 
    for x in range(0,len(urls)):
        rq = requests.get(urls[x])

        with open("aps_data.csv", "wb") as f:
            f.write(rq.content)

        df = pd.read_csv("aps_data.csv")

        
        reshaped = df.pivot_table(
            index=["GEOGRAPHY_NAME", "VARIABLE_NAME"],
            columns="MEASURES_NAME",
            values="OBS_VALUE"
        ).reset_index()

        renamed = reshaped.pivot_table(
        index=["GEOGRAPHY_NAME"],
        columns="VARIABLE_NAME",
        values=["Confidence", "Numerator", "Denominator", "Variable"]
        ).reset_index()

        renamed.drop(columns=["Confidence","Denominator"],inplace=True)
        renamed["Numerator"] = renamed["Numerator"].astype(int)

        renamed.to_csv(url_names[x])
        os.remove("aps_data.csv")

    merged = pd.merge(pd.read_csv("Number_of_Employed.csv"),pd.read_csv("Employment_Percentage.csv"),on="GEOGRAPHY_NAME",how="inner")
    merged.drop(columns=["Variable_x","MEASURES_NAME_y","Numerator_y","MEASURES_NAME_x"],inplace=True)
    merged.columns = ["Local Authority", "numbers", "%"]
    merged.to_csv(f"Employment_{formatted_date}.csv",index=False)

    for name in url_names:
        os.remove(name)
   


    


if __name__ == "__main__":
    Employment_Conversion()